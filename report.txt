실험1: dataset_13으로 학습 및 평가 -> 재현 가능성 검증 -> test mAP50: 0.52 로 재현이 가능했다. (original: 0.55)


----------------------------- 배경합성 알고리즘이 문제인지, crawling 데이터셋이 문제인지 확인 --------------------
실험2: CUB200 데이터셋만으로 (0, 0, 0), (1, 1, 1)로 어그멘테이션해서 실험, test mAP: 0.346
실험3: CUB200 데이터셋만으로 (0, 0, 0), (15, 3, 1)로 어그멘테이션해서 실험, test mAP: 0.359
실험4: CUB200 데이터셋만으로 (20000, 2000, 0), (15, 3, 1)로 어그멘테이션해서 실험, test mAP: 0.265
실험5: CUB200 + crawling 데이터셋으로 (0, 0, 0), (1, 1, 1)로 어그멘테이션해서 실험, test mAP: 0.449
실험6: CUB200 + crawling 데이터셋으로 (0, 0, 0), (15, 3, 1)로 어그멘테이션해서 실험, test mAP: 0.217
실험7: CUB200 + crawling 데이터셋으로 (20000, 2000, 0), (15, 3, 1)로 어그멘테이션해서 실험, test mAP: 0.193
실험8: CUB200 + crawling 데이터셋으로 (40000, 4000, 0), (25, 15, 1)로 어그멘테이션해서 실험, test mAP: 0.208

----> 배경 합성 알고리즘이 오히려 도움이 되지 못하였다.


--------------------------- validset과 testset의 성능 차이가 많이 나는 원인 찾기 -----------------
실험9: 위 실험2 ~ 실험7 중 가장 성능이 좋았던 모델로 한 번 더 학습하고, validset과 testset을 변경하여 학습 진행
학습 데이터는 같았지만, 학습시에 체크하는 것인지 학습하고 난 후에 체크하는 것인지에 따라 성능이 천차만별이었다.
mAP: 0.392


실험10: 변경된 배경합성 알고리즘으로 CUB200 + crawling (10000, 1000, 0), (10, 5, 1)로 어그멘테이션해서 실험, test mAP: 0.206


----------------------------------------- test_images 에 대한 성능 순위 -------------------------------
1st: experiment8
2nd: experiment2
3rd: experiment10
4th: experiment5
5th: experiment6
6th: experiment7
7th: experiment4

------------------------------------- 모델 복잡도 -------------------------------------

실험11: CUB200 dataset을 기본 배경합성 알고리즘으로 (40000, 2000, 0), (30, 15, 1)로 어그멘테이션해서 m 복잡도로 학습한다, test mAP: 0.256
실험12: CUB200 dataset을 기본 배경합성 알고리즘으로 (40000, 2000, 0), (30, 15, 1)로 어그멘테이션해서 l 복잡도로 학습한다, test mAP: 0.294
실험13: CUB200 dataset을 기본 배경합성 알고리즘으로 (40000, 2000, 0), (30, 15, 1)로 어그멘테이션해서 x 복잡도로 학습한다, test mAP: 0.279
실험14: CUB200 dataset을 기본 배경합성 알고리즘으로 (40000, 2000, 0), (30, 15, 1)로 어그멘테이션해서 s 복잡도로 학습한다, test mAP: 0.21

실험15: CUB200 + crawling dataset을 기본 배경합성 알고리즘(배경 합성의 조류 변환 부분에서 RandomFog 부분을 제거함)으로 (40000, 2000, 0), (20, 10, 1)로 어그멘테이션해서 l 복잡도로 학습한다, test mAP: 0.251

-------------------------------------- 배경 합성 알고리즘 -------------------------------------

실험16: 배경 합성 알고리즘의 random resize 부분을 scale_factor를 정규분포에서 추출하여 수행하도록 변경한다., val mAP: 0.584, test mAP: 0.25
실험17: 배경 합성 알고리즘의 ioa 부분을 iof와 iob로 바꾸어 처리하도록 변경한다. val mAP: 0.941, test mAP: 0.988
실험18: 수정된 배경 합성 알고리즘으로 (40000, 2000, 0), (10, 5, 1) 로 어그멘테이션해서 m 사이즈로 epochs 25번 학습한다. test mAP: 0.983 (crow_img.jpg 예측함)
실험19: 수정된 배경 합성 알고리즘으로 (40000, 2000, 0), (10, 5, 1) 로 어그멘테이션해서 m 사이즈로 epochs 50번 학습한다. test mAP: 0.989
실험20: 수정된 배경 합성 알고리즘으로 (50000, 3000, 0), (20, 10, 1) 로 어그멘테이션해서 l 사이즈로 epochs 50번 학습한다. test mAP: 0.994
실험22: 수정된 배경 합성 알고리즘으로 (30000, 2000, 0), (20, 10, 1) 로 어그멘테이션해서 m 사이즈로 epochs 25번 학습한다. test mAP: 
실험23: 수정된 배경 합성 알고리즘으로 (30000, 2000, 0), (20, 10, 1) 로 어그멘테이션해서 s 사이즈로 epochs 20번 학습한다. test mAP: 0.993
실험24: 수정된 배경 합성 알고리즘으로 ((10000, 10000, 10000), (1000, 1000, 1000), 0), (20, 10, 1) 로 어그멘테이션해서 s 사이즈로 epochs 25 번 학습한다. test mAP: 0.921 (til epochs 0)
실험25: 배경 합성 알고리즘으로 ((10000, 10000, 10000), (1000, 1000, 1000), 0), (25, 15, 1) 로 어그멘테이션해서 s 사이즈로 epochs 30 번 학습한다. val mAP50: 0.971, val mAP50-95: 0.801, test mAP50: 0.989, test mAP50-95: 0.832 (날아다니거나 작은 객체에 대해서 예측 성능 가장 뛰어남)
실험26: 배경 합성 알고리즘으로 ((10000, 10000, 10000), (1000, 1000, 1000), 0), (25, 15, 1) 로 어그멘테이션해서 m 사이즈로 epochs 30 번 학습한다. val mAP50: 0.966, val mAP50-95: 0.788, test mAP50: 0.986, test mAP50-95: 0.814
실험27: 배경 합성 알고리즘으로 ((10000, 10000, 10000), (1000, 1000, 1000), 0), (25, 15, 1) 로 어그멘테이션해서 s 사이즈로 epochs 50 번 학습한다. val mAP50: 0.969, val mAP50-95: 0.804, test mAP50: 0.988, test mAP50-95: 0.833
실험28: 배경 합성 알고리즘으로 ((10000, 10000, 10000), (1000, 1000, 1000), 0), (25, 15, 1) 로 어그멘테이션해서 m 사이즈로 epochs 100 번 학습한다. val mAP50: , val mAP50-95: , test mAP50: , test mAP50-95: 
- 날아다니거나 작은 객체에 대해서 예측 성능 아주 뛰어남
- 잘못 검출하는 경우가 많음 -> 배경 이미지에 더 다양한 이미지를 추가하여 성능 개선이 가능할 것 같다.)
- 오검출률만 제외하면 예측 안정성은 만족스러웠다

실험29: 수정된 배경 합성 알고리즘과 추가된 배경 데이터셋으로 ((15000, 15000, 15000), (1000, 1000, 1000), 0), (30, 15, 1) 로 어그멘테이션해서 m 사이즈로 epochs 100 번 학습한다. val mAP50: 0.975, val mAP50-95: 0.801, test mAP50: , test mAP50-95:  (til epochs 27)
실험30: 추가된 배경 데이터셋으로 ((15000, 15000, 15000), (1000, 1000, 1000), 0), (30, 15, 1) 로 어그멘테이션해서 m 사이즈로 epochs 100 번 학습한다. val mAP50: 0.976, val mAP50-95: 0.829, test mAP50: 0.986, test mAP50-95: 0.832
- 얼굴을 잘못 인식하는 문제가 많이 개선되었다.
실험31: 추가된 배경 데이터셋으로 ((15000, 15000, 15000), (1000, 1000, 1000), 0), (30, 15, 1) 로 어그멘테이션해서 s 사이즈로 epochs 100 번 학습한다. val mAP50: 0.974, val mAP50-95: 0.812, test mAP50: 0.989, test mAP50-95: 0.834
실험32: 수정된 배경 합성 알고리즘으로 ((20000, 15000, 15000), (4000, 3000, 3000), 0), (30, 7, 1) 로 어그멘테이션해서 m 사이즈로 epochs 100 번 학습한다. val mAP50: 0.966, val mAP50-95: 0.826, test mAP50: 0.985, test mAP50-95: 0.84
실험33: 배경 합성 알고리즘으로 ((20000, 15000, 15000), (4000, 3000, 3000), 0), (30, 7, 1) 로 어그멘테이션해서 s 사이즈로 epochs 50 번 학습한다. val mAP50: 0.962, val mAP50-95: 0.8, test mAP50: 0.984, test mAP50-95: 0.837
실험34: 수정된 배경 합성 알고리즘으로 ((15000, 15000, 15000), (3000, 3000, 3000), 0), (30, 15, 1) 로 어그멘테이션해서 m 사이즈로 epochs 100번 학습한다. val mAP50: 0.975, val mAP50-95: 0.835, test mAP50: 0.985, test mAP50-95: 0.836